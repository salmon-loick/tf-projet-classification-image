{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Première partie : Classification d’images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\loick\\tensorflow_datasets\\cats_vs_dogs\\4.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Size...: 100%|██████████| 824887076/824887076 [00:00<00:00, 137485681001.99 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 111.13 url/s]\n",
      "                                                                \r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"There is no item named 'PetImages\\\\\\\\Cat\\\\\\\\0.jpg' in the archive\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcats_vs_dogs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:649\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03m`tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m    Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    643\u001b[0m dbuilder \u001b[38;5;241m=\u001b[39m _fetch_builder(\n\u001b[0;32m    644\u001b[0m     name,\n\u001b[0;32m    645\u001b[0m     data_dir,\n\u001b[0;32m    646\u001b[0m     builder_kwargs,\n\u001b[0;32m    647\u001b[0m     try_gcs,\n\u001b[0;32m    648\u001b[0m )\n\u001b[1;32m--> 649\u001b[0m \u001b[43m_download_and_prepare_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m   as_dataset_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:508\u001b[0m, in \u001b[0;36m_download_and_prepare_builder\u001b[1;34m(dbuilder, download, download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m    507\u001b[0m   download_and_prepare_kwargs \u001b[38;5;241m=\u001b[39m download_and_prepare_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m--> 508\u001b[0m   dbuilder\u001b[38;5;241m.\u001b[39mdownload_and_prepare(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdownload_and_prepare_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:691\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mread_from_directory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 691\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m   \u001b[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[0;32m    697\u001b[0m   \u001b[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[0;32m    698\u001b[0m   \u001b[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[0;32m    699\u001b[0m   \u001b[38;5;66;03m# when reading from package data.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdownload_size \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownloaded_size\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1584\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m   1572\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m split_name, generator \u001b[38;5;129;01min\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m   1573\u001b[0m       split_generators\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1574\u001b[0m       desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating splits...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1575\u001b[0m       unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m splits\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1576\u001b[0m       leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1577\u001b[0m   ):\n\u001b[0;32m   1578\u001b[0m     filename_template \u001b[38;5;241m=\u001b[39m naming\u001b[38;5;241m.\u001b[39mShardedFileTemplate(\n\u001b[0;32m   1579\u001b[0m         split\u001b[38;5;241m=\u001b[39msplit_name,\n\u001b[0;32m   1580\u001b[0m         dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m   1581\u001b[0m         data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[0;32m   1582\u001b[0m         filetype_suffix\u001b[38;5;241m=\u001b[39mpath_suffix,\n\u001b[0;32m   1583\u001b[0m     )\n\u001b[1;32m-> 1584\u001b[0m     future \u001b[38;5;241m=\u001b[39m \u001b[43msplit_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_split_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_shuffling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_shuffling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1590\u001b[0m     split_info_futures\u001b[38;5;241m.\u001b[39mappend(future)\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;66;03m# Process the result of the beam pipeline.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:341\u001b[0m, in \u001b[0;36mSplitBuilder.submit_split_generation\u001b[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Depending on the type of generator, we use the corresponding\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# `_build_from_xyz` method.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generator, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[1;32m--> 341\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_from_generator(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuild_kwargs)\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Otherwise, beam required\u001b[39;00m\n\u001b[0;32m    343\u001b[0m   unknown_generator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    344\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid split generator value for split `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    345\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected generator or apache_beam object. Got: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    346\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(generator)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    347\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:406\u001b[0m, in \u001b[0;36mSplitBuilder._build_from_generator\u001b[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001b[0m\n\u001b[0;32m    396\u001b[0m serialized_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features\u001b[38;5;241m.\u001b[39mget_serialized_info()\n\u001b[0;32m    397\u001b[0m writer \u001b[38;5;241m=\u001b[39m writer_lib\u001b[38;5;241m.\u001b[39mWriter(\n\u001b[0;32m    398\u001b[0m     serializer\u001b[38;5;241m=\u001b[39mexample_serializer\u001b[38;5;241m.\u001b[39mExampleSerializer(serialized_info),\n\u001b[0;32m    399\u001b[0m     filename_template\u001b[38;5;241m=\u001b[39mfilename_template,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m     shard_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shard_config,\n\u001b[0;32m    405\u001b[0m )\n\u001b[1;32m--> 406\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, example \u001b[38;5;129;01min\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m    407\u001b[0m     generator,\n\u001b[0;32m    408\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m examples...\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    409\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    410\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal_num_examples,\n\u001b[0;32m    411\u001b[0m     leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    412\u001b[0m     mininterval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    413\u001b[0m ):\n\u001b[0;32m    414\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    415\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features\u001b[38;5;241m.\u001b[39mencode_example(example)\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\loick\\Desktop\\DataScience\\Tensorflow\\tf-projet-classification-image\\.venv\\lib\\site-packages\\tensorflow_datasets\\image_classification\\cats_vs_dogs.py:117\u001b[0m, in \u001b[0;36mCatsVsDogs._generate_examples\u001b[1;34m(self, archive)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m new_zip:\n\u001b[0;32m    116\u001b[0m   new_zip\u001b[38;5;241m.\u001b[39mwritestr(fname, img_recoded\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m--> 117\u001b[0m new_fobj \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m record \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: new_fobj,\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage/filename\u001b[39m\u001b[38;5;124m\"\u001b[39m: fname,\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: label,\n\u001b[0;32m    123\u001b[0m }\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m fname, record\n",
      "File \u001b[1;32mc:\\Users\\loick\\Software\\Python\\Python310\\lib\\zipfile.py:1516\u001b[0m, in \u001b[0;36mZipFile.open\u001b[1;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[0;32m   1513\u001b[0m     zinfo\u001b[38;5;241m.\u001b[39m_compresslevel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompresslevel\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1515\u001b[0m     \u001b[38;5;66;03m# Get info object for name\u001b[39;00m\n\u001b[1;32m-> 1516\u001b[0m     zinfo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_to_write(zinfo, force_zip64\u001b[38;5;241m=\u001b[39mforce_zip64)\n",
      "File \u001b[1;32mc:\\Users\\loick\\Software\\Python\\Python310\\lib\\zipfile.py:1443\u001b[0m, in \u001b[0;36mZipFile.getinfo\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1441\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNameToInfo\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m   1444\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere is no item named \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m in the archive\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "\u001b[1;31mKeyError\u001b[0m: \"There is no item named 'PetImages\\\\\\\\Cat\\\\\\\\0.jpg' in the archive\""
     ]
    }
   ],
   "source": [
    "dataset = tfds.load('cats_vs_dogs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
